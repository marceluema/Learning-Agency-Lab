{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08bbfbf-bf6f-42ce-af87-92253cbc07b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marce\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58be10d2-c579-49d9-89e5-073b9f7dec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "# Função para calcular o índice Flesch-Kincaid\n",
    "def calculate_flesch_kincaid(text):\n",
    "    # Usando a biblioteca textstat para calcular o índice Flesch-Kincaid\n",
    "    return textstat.flesch_kincaid_grade(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea52ef6-080d-45d9-b7ec-d83a10fa455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import language_tool_python\n",
    "\n",
    "# Carregar modelo do spaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Instanciar o LanguageTool\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "# Funções para extração de características\n",
    "def count_grammar_errors(text):\n",
    "    # Use o objeto LanguageTool para verificar erros gramaticais no texto\n",
    "    matches = tool.check(text)\n",
    "    return len(matches)\n",
    "\n",
    "def calculate_coherence(doc):\n",
    "    # Convertendo doc.sents em uma lista para acessar sequencialmente\n",
    "    sents_list = list(doc.sents)\n",
    "    # Exemplo simples para calcular a média da coerência\n",
    "    return np.mean([sent.similarity(next_sent) for sent, next_sent in zip(sents_list, sents_list[1:])])\n",
    "\n",
    "def calculate_lexical_diversity(doc):\n",
    "    # Exemplo simples para calcular a diversidade lexical\n",
    "    return len(set([token.text.lower() for token in doc])) / len(doc)\n",
    "\n",
    "def count_named_entities(doc):\n",
    "    # Exemplo simples para contar entidades nomeadas\n",
    "    return len([ent for ent in doc.ents])\n",
    "\n",
    "\n",
    "# Adicionando o cálculo do Flesch-Kincaid no extrator de características\n",
    "class TextFeaturesExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nlp):\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for doc in self.nlp.pipe(X):\n",
    "            features.append([\n",
    "                len(doc),  # Comprimento do texto\n",
    "                count_grammar_errors(doc.text),  # Número de erros gramaticais\n",
    "                calculate_coherence(doc),  # Medida de coerência\n",
    "                calculate_lexical_diversity(doc),  # Diversidade lexical\n",
    "                count_named_entities(doc),  # Número de entidades nomeadas\n",
    "                calculate_flesch_kincaid(doc.text)  # Índice Flesch-Kincaid\n",
    "            ])\n",
    "        return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0acd0e-2403-45a4-be61-79000d623bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329e8c1a-3e63-4fb1-a2cb-ce2f1e077c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "3    6280\n",
       "2    4723\n",
       "4    3926\n",
       "1    1252\n",
       "5     970\n",
       "6     156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5d6a84-7343-4c0b-83a5-a1404a796ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remover somnete as quebras de linhas e deixar em minuscula\n",
    "df['full_text']=df['full_text'].str.lower().str.replace('\\n', ' ')\n",
    "\n",
    "#remover pontuação\n",
    "df['full_text']=df['full_text'].apply(lambda x: re.sub(r'^\\s*|\\s*$|[^\\w\\s]|[\\d]', ' ', str(x))).str.lower().str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc76b457-36ee-410e-ad95-e3d70ada7d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score\n",
       "1    200\n",
       "2    200\n",
       "3    200\n",
       "4    200\n",
       "5    200\n",
       "6    156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = 200\n",
    "\n",
    "def sample (df, group_column, n):\n",
    "    return df.groupby(group_column).apply(lambda x: x.sample(n=min(len(x), n))).reset_index(drop=True)\n",
    "\n",
    "filter = df[df['score'].isin([1,2,3,4,5,6])]\n",
    "\n",
    "df_sample = sample(filter, 'score', n_sample)\n",
    "df_sample['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa31fd9-5c50-4c7a-9f7f-1322636ed201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_20488\\3493551176.py:22: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Span.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  return np.mean([sent.similarity(next_sent) for sent, next_sent in zip(sents_list, sents_list[1:])])\n"
     ]
    }
   ],
   "source": [
    "# Instanciar o extrator de características\n",
    "extractor = TextFeaturesExtractor(nlp)\n",
    "\n",
    "# Aplicar a transformação no DataFrame\n",
    "features_array = extractor.transform(df_sample['full_text'])\n",
    "\n",
    "# Criar novas colunas no DataFrame com as características extraídas\n",
    "df_sample['comprimento_texto'] = features_array[:, 0]\n",
    "df_sample['num_grammatical_errors'] = features_array[:, 1]\n",
    "df_sample['coherence_score'] = features_array[:, 2]\n",
    "df_sample['lexical_diversity'] = features_array[:, 3]\n",
    "df_sample['num_named_entities'] = features_array[:, 4]\n",
    "df_sample['Flesch-Kincaid'] = features_array[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ca64f9-9161-4f75-ab53-ead0b4995679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>comprimento_texto</th>\n",
       "      <th>num_grammatical_errors</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>num_named_entities</th>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814624</td>\n",
       "      <td>0.668643</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>-0.675155</td>\n",
       "      <td>0.348910</td>\n",
       "      <td>0.814630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprimento_texto</th>\n",
       "      <td>0.814624</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900317</td>\n",
       "      <td>0.292852</td>\n",
       "      <td>-0.728580</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.998863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_grammatical_errors</th>\n",
       "      <td>0.668643</td>\n",
       "      <td>0.900317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268388</td>\n",
       "      <td>-0.597440</td>\n",
       "      <td>0.651028</td>\n",
       "      <td>0.885380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coherence_score</th>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.292852</td>\n",
       "      <td>0.268388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194919</td>\n",
       "      <td>0.182756</td>\n",
       "      <td>0.287756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lexical_diversity</th>\n",
       "      <td>-0.675155</td>\n",
       "      <td>-0.728580</td>\n",
       "      <td>-0.597440</td>\n",
       "      <td>-0.194919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.297744</td>\n",
       "      <td>-0.730094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_named_entities</th>\n",
       "      <td>0.348910</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.651028</td>\n",
       "      <td>0.182756</td>\n",
       "      <td>-0.297744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "      <td>0.814630</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>0.885380</td>\n",
       "      <td>0.287756</td>\n",
       "      <td>-0.730094</td>\n",
       "      <td>0.526345</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           score  comprimento_texto  num_grammatical_errors  \\\n",
       "score                   1.000000           0.814624                0.668643   \n",
       "comprimento_texto       0.814624           1.000000                0.900317   \n",
       "num_grammatical_errors  0.668643           0.900317                1.000000   \n",
       "coherence_score         0.336449           0.292852                0.268388   \n",
       "lexical_diversity      -0.675155          -0.728580               -0.597440   \n",
       "num_named_entities      0.348910           0.538793                0.651028   \n",
       "Flesch-Kincaid          0.814630           0.998863                0.885380   \n",
       "\n",
       "                        coherence_score  lexical_diversity  \\\n",
       "score                          0.336449          -0.675155   \n",
       "comprimento_texto              0.292852          -0.728580   \n",
       "num_grammatical_errors         0.268388          -0.597440   \n",
       "coherence_score                1.000000          -0.194919   \n",
       "lexical_diversity             -0.194919           1.000000   \n",
       "num_named_entities             0.182756          -0.297744   \n",
       "Flesch-Kincaid                 0.287756          -0.730094   \n",
       "\n",
       "                        num_named_entities  Flesch-Kincaid  \n",
       "score                             0.348910        0.814630  \n",
       "comprimento_texto                 0.538793        0.998863  \n",
       "num_grammatical_errors            0.651028        0.885380  \n",
       "coherence_score                   0.182756        0.287756  \n",
       "lexical_diversity                -0.297744       -0.730094  \n",
       "num_named_entities                1.000000        0.526345  \n",
       "Flesch-Kincaid                    0.526345        1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular a correlação entre as variáveis\n",
    "correlation_matrix = df_sample[['score', 'comprimento_texto', 'num_grammatical_errors', 'coherence_score', 'lexical_diversity', 'num_named_entities',\n",
    "                               'Flesch-Kincaid']].corr()\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f06d8a-6a00-41b2-a716-3cf04b9afc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar os dados para o modelo de classificação\n",
    "X = df_sample[['comprimento_texto', 'num_grammatical_errors', 'lexical_diversity', 'num_named_entities','Flesch-Kincaid']]\n",
    "y = df_sample['score']\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "910e4559-829b-4b9b-86bf-ff33c19c5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.47 (+/- 0.11)\n",
      "Relatório de Classificação - Conjunto de Teste:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.56      0.52        39\n",
      "           2       0.60      0.64      0.62        45\n",
      "           3       0.46      0.36      0.40        47\n",
      "           4       0.36      0.41      0.38        34\n",
      "           5       0.49      0.42      0.45        40\n",
      "           6       0.61      0.63      0.62        27\n",
      "\n",
      "    accuracy                           0.50       232\n",
      "   macro avg       0.50      0.51      0.50       232\n",
      "weighted avg       0.50      0.50      0.50       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# usando regressão logistica \n",
    "classify = Pipeline([\n",
    "    ('classifier', LogisticRegression(max_iter=10000, random_state=42))])\n",
    "\n",
    "# Treinar o modelo no conjunto de treino completo\n",
    "classify.fit(X_train, y_train)\n",
    "\n",
    "# Obter as previsões no conjunto de teste\n",
    "y_test_pred = classify.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(classify, X_test, y_test, cv=4, scoring='f1_macro')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Calcular e exibir o relatório de classificação para o conjunto de teste\n",
    "test_report = classification_report(y_test, y_test_pred, digits=2)\n",
    "print(\"Relatório de Classificação - Conjunto de Teste:\\n\", test_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
